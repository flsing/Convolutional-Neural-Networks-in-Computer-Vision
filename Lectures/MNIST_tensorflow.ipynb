{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hello World Example**\n",
    "\n",
    "_This notebook is partly based on Chapter 9, 11 and 13 of Aurelien Geron: Hand-on Machine Learning with Scikit-learn & Tensorflow._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "NB_ID = \"MNIST_tensorflow\"\n",
    "\n",
    "# create the directory if it does not exist\n",
    "os.makedirs(os.path.join(PROJECT_ROOT_DIR, \"images\", NB_ID), exist_ok = True)\n",
    "        \n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", NB_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple utility functions to plot grayscale and RGB images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image):\n",
    "    plt.imshow(image, cmap=\"gray\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def plot_color_image(image):\n",
    "    plt.imshow(image.astype(np.uint8),interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course we will need TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(2, name=\"x\")\n",
    "y = tf.Variable(3, name=\"y\")\n",
    "f = 3*x*x + 2*y*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "  # initialize variables\n",
    "  x.initializer.run() # initializes x to 2\n",
    "  y.initializer.run() # initializes y to 3\n",
    "  result = f.eval() # runs the graph and assigns to result\n",
    "  # session closes with end of block\n",
    "\n",
    "print(result) # Will print 24\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's manipulate a second graph just because we can**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  # graph becomes default\n",
    "  z = tf.Variable( 1, \"z in graph\" )\n",
    "  # graph ends as default with end of block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is x in default? True \n",
      "Is z in graph? True \n"
     ]
    }
   ],
   "source": [
    "print( \"Is x in default? {} \".format( x.graph is tf.get_default_graph() ))\n",
    "print( \"Is z in graph? {} \".format( z.graph is graph ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Autodiff with tf.gradients** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.0\n",
      "[18.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "x = tf.Variable(2.0, name=\"x\")\n",
    "y = tf.Variable(3.0, name=\"y\")\n",
    "\n",
    "f = 3*x*x + 2*y*x\n",
    "\n",
    "gF = tf.gradients(f, [x, y])\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  sess.run(init)\n",
    "  result = f.eval()\n",
    "  gradF = sess.run(gF)\n",
    "\n",
    "print(result)\n",
    "print(gradF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST from scratch\n",
    "\n",
    "Test and Training Data: Let's split into training images and test images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constants for network configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nInputs = 28*28  # MNIST\n",
    "nHidden1 = 300\n",
    "nHidden2 = 100\n",
    "nOutputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, nInputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Layer\n",
    "\n",
    "Define a dense layer from scratch. Code Aurelien Geron: Hand-on Machine Learning, Chpt. 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"kernel\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"MLP\"):\n",
    "    hidden1 = neuron_layer(X, nHidden1, name=\"hidden1\", activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, nHidden2, name=\"hidden2\", activation=tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, nOutputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20181120140826\n"
     ]
    }
   ],
   "source": [
    "# Keep log files separate for each run by\n",
    "# using current date and time\n",
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "print(now)\n",
    "rootDir = \"tb_logs\" # use a directory relative to current dir \n",
    "# logDir = \"{}/log_{}/\".format(rootDir,now)\n",
    "# For this example we keep it all in one log file\n",
    "logDir = \"{}/log_test/\".format(rootDir,now)\n",
    "\n",
    "# write the graph â€“ here we assume that the graph is the default\n",
    "fw = tf.summary.FileWriter(logDir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchAcc = tf.summary.scalar('Batch_Acc.', accuracy )\n",
    "validAcc = tf.summary.scalar('Valid_Acc.', accuracy )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.9 Val accuracy: 0.9146\n",
      "1 Batch accuracy: 0.92 Val accuracy: 0.936\n",
      "2 Batch accuracy: 0.96 Val accuracy: 0.945\n",
      "3 Batch accuracy: 0.92 Val accuracy: 0.9512\n",
      "4 Batch accuracy: 0.98 Val accuracy: 0.9558\n",
      "5 Batch accuracy: 0.96 Val accuracy: 0.9566\n",
      "6 Batch accuracy: 1.0 Val accuracy: 0.9612\n",
      "7 Batch accuracy: 0.94 Val accuracy: 0.9628\n",
      "8 Batch accuracy: 0.98 Val accuracy: 0.965\n",
      "9 Batch accuracy: 0.96 Val accuracy: 0.9658\n",
      "10 Batch accuracy: 0.92 Val accuracy: 0.9686\n",
      "11 Batch accuracy: 0.98 Val accuracy: 0.9688\n",
      "12 Batch accuracy: 0.98 Val accuracy: 0.967\n",
      "13 Batch accuracy: 0.98 Val accuracy: 0.9708\n",
      "14 Batch accuracy: 1.0 Val accuracy: 0.9712\n",
      "15 Batch accuracy: 0.94 Val accuracy: 0.973\n",
      "16 Batch accuracy: 1.0 Val accuracy: 0.9732\n",
      "17 Batch accuracy: 1.0 Val accuracy: 0.9742\n",
      "18 Batch accuracy: 1.0 Val accuracy: 0.9744\n",
      "19 Batch accuracy: 0.98 Val accuracy: 0.975\n",
      "20 Batch accuracy: 1.0 Val accuracy: 0.9754\n",
      "21 Batch accuracy: 1.0 Val accuracy: 0.976\n",
      "22 Batch accuracy: 0.98 Val accuracy: 0.9762\n",
      "23 Batch accuracy: 0.98 Val accuracy: 0.975\n",
      "24 Batch accuracy: 0.98 Val accuracy: 0.977\n",
      "25 Batch accuracy: 1.0 Val accuracy: 0.9772\n",
      "26 Batch accuracy: 0.98 Val accuracy: 0.978\n",
      "27 Batch accuracy: 1.0 Val accuracy: 0.9772\n",
      "28 Batch accuracy: 0.96 Val accuracy: 0.9754\n",
      "29 Batch accuracy: 0.98 Val accuracy: 0.9776\n",
      "30 Batch accuracy: 1.0 Val accuracy: 0.9754\n",
      "31 Batch accuracy: 0.98 Val accuracy: 0.977\n",
      "32 Batch accuracy: 0.98 Val accuracy: 0.9772\n",
      "33 Batch accuracy: 0.98 Val accuracy: 0.979\n",
      "34 Batch accuracy: 1.0 Val accuracy: 0.9786\n",
      "35 Batch accuracy: 1.0 Val accuracy: 0.978\n",
      "36 Batch accuracy: 0.98 Val accuracy: 0.978\n",
      "37 Batch accuracy: 1.0 Val accuracy: 0.9776\n",
      "38 Batch accuracy: 1.0 Val accuracy: 0.979\n",
      "39 Batch accuracy: 1.0 Val accuracy: 0.9776\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        batch_index = 0;\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            batch_index = batch_index + batch_size\n",
    "            if batch_index % 10 == 0:\n",
    "                bAcc = batchAcc.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * batch_size + batch_index\n",
    "                fw.add_summary( bAcc, step )\n",
    "                vAcc = validAcc.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "                fw.add_summary( vAcc, step )\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Batch accuracy:\", acc_batch, \"Val accuracy:\", acc_val)\n",
    "\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Layer\n",
    "\n",
    "Define a CNN layer from scratch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is assumed to be of shape batchSize, width, height, nChannels\n",
    "\n",
    "def cnn_layer(X, filterSz, nFilters, name, stride=1, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        # random initialization of filters\n",
    "        stddev = 2 / np.sqrt(int(X.get_shape()[3])+nFilters)\n",
    "        init = tf.truncated_normal((filterSz,filterSz,\n",
    "                                    int(X.get_shape()[3]),nFilters), \n",
    "                                    stddev=stddev)\n",
    "        filt = tf.Variable(init, name=\"filt\")\n",
    "        # 4D inputs, filters, output\n",
    "        Z_conv = tf.nn.conv2d(X, filt, \n",
    "                              strides=[1,stride,stride,1], padding=\"SAME\")\n",
    "        if activation is not None:\n",
    "            return activation(Z_conv)\n",
    "        else:\n",
    "            return "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
